# AI Governance Card: AI-Powered Coding Assistance Tools

* Last Revised: `01/22/26`
* Date Issued: `01/27/2026`
* Version: `2.0`
* Author: Solomon Abiola, Lauren Maffeo

## 1.0 Purpose and Scope

â€‹â€‹This governance card forms foundational guidelines for use of AI-powered coding assistants within Marylandâ€™s State government. It builds upon the Stateâ€™s existing frameworks, including:â€‹

* [Maryland's Responsible AI Policy](https://doit.maryland.gov/policies/ai/Pages/maryland-responsible-ai-policy.aspx)
* [Executive Order Catalyzing the Responsible and Productive Use of Artificial Intelligence in Maryland State Government](https://governor.maryland.gov/Lists/ExecutiveOrders/Attachments/31/EO%2001.01.2024.02%20Catalyzing%20the%20Responsible%20and%20Productive%20Use%20of%20Artificial%20Intelligence%20in%20Maryland%20State%20Government_Accessible.pdf)
* [SB818](https://mgaleg.maryland.gov/2024RS/bills/sb/sb0818E.pdf)

â€‹Marylandâ€™s governance card on AI coding assistants applies to all Executive Branch agencies and all personnel (employees, contractors, and consultants) who develop, maintain, or leverage AI systems to provide services to the State. While agencies must adopt this guidance in its entirety, they can require more stringent guidelines based on their own operational context.â€‹â€‹

## 2.0 Definition and Autonomy Levels

â€‹â€‹AI-powered coding assistants use generative AI to suggest code completions, generate functions, or provide chatbot assistance. While these tools can increase productivity by automating boilerplate tasks, they do not replace developer expertise.

â€‹Developers remain 100% responsible for the final versions of any outputs that AI coding assistants produce. The State correlates risk with the level of autonomy per type of coding assistant:â€‹â€‹

![Coding Assistant Autonomy Levels](images/Coding%20Assistant%20Autonomy%20Levels%20produce.png)

### Low Autonomy (Code Completion): â€‹â€‹
The tool offers single-line suggestions as the developer types (for example, GitHub Copilot inline). The developer acts as the primary author, and risk is minimal/limited because human review is constant.

### â€‹â€‹Medium Autonoâ€‹my (Conversational/Batch):
The tool generates large code blocks based on prompts (for example, Google AI Studio). The developer acts as a reviewer/editor, and risk is limited, mitigated by the deliberate human action of copying and pasting the code.â€‹â€‹

### â€‹â€‹High Autonomy (Agentic/Asynchronous):
â€‹â€‹The tool can perform sequential steps like editing files and running commands (for example, Jules, Cline). The developer provides oversight and approval, but risk is high due to the potential for unintended changes or data leakage.

## 3.0 Risk Classification

â€‹â€‹According to the standards in the State of Marylandâ€™s AI risk assessment matrix, AI coding assistants are broadly classified as Limited Risk because they do not autonomously decide critical outcomes for individuals. Human developers and testers are the final decision-makers, because Maryland does not allow AI to make autonomous choices when used for State business.

â€‹â€‹However, the risk tier escalates to High if state staff giveâ€‹ coding assistants access to sensitive files, ask it to execute commands without explicit approval, or if the tool's privacy settings enable data training. Additionally, Maryland law prohibits using coding assistants from companies based outside of the U.S. (e.g., Mistral, Qwen) due to physical access control requirements.

## 4.0 Developer Roadmap (â€‹Mandatory Doâ€™â€‹s and Donâ€™ts)â€‹â€‹

![Coding Assistant Implementation Roadmap](images/Coding%20Assistant%20Implementation%20Roadmap.png)

### Phase 1: Setup and Configurationâ€‹â€‹â€‹

* **Approved Versions:** Use only **Enterprise or Government** versions of coding assistants; individual or free versions often default to data training and are prohibited.
* **Privacy Hardening:** You **must uncheck** _"Allow vendor to use code for training"_ and enable filters that block suggestions matching public code.
* **Limit Access:** Write permissions files (e.g., .gitignore, .copilotignore) to explicitly block the AI from reading sensitive directory segments or environment files containing secrets.

### Phase 2: Responsible Usageâ€‹â€‹â€‹

* **Zero Sensitive Data:** Never input PII, PHI, or authentication secrets (API keys, passwords). If code must be generated for a sensitive field, use an abstract placeholder (e.g., USER_SSN).
* **Human-in-the-Loop:** Treat AI as a junior developer: Helpful but potentially flawed. Review every suggestion for correctness, security vulnerabilities (like SQL injection or weak cryptography), and adherence to team style standards.
* **Sanitize Environments:** Use only synthetic data for development and testing.

### Phase 3: Final Checks and Commitsâ€‹â€‹â€‹

* **Validation:** All significant AI-generated code must undergo peer review and rigorous unit/integration testing.
* **Automated Scans:** Run static analysis (linters), secret scanning, and code quality checks before merging.
* **Accountability:** Before committing, **you must fully understand the code and be able to explain how it works:** _"AI did it"_ is not an acceptable excuse for bugs or security incidents.

## 5.0 Risk Analysis and Mitigation

![AI Coding Assistants Risk and Mitigation](images/AI%20Coding%20Assistants%20Risk%20and%20Mitigation.png)

* **Intellectual Property and Copyright:** AI may reproduce licensed code verbatim, raising the risk of copyright infringement or license violations.
    * **Mitigation:** Enable public code filters. If a coding assistant suggests a substantial block of text, manually search public repositories to ensure compliance with open source licenses.
* **Data Leakage:** Cloud-based tools may send proprietary state code as prompts to external services.
    * **Mitigation:** Use FedRAMP-authorized Government clouds where data remains within the U.S. and is not used for model training.
* **Security Vulnerabilities:** AI can suggest outdated algorithms (e.g., MD5) or be manipulated via rules file backdoors to insert malicious instructions.
    * **Mitigation:** Perform dynamic analysis and penetration testing on all output that coding assistants produce.
* **Automation Bias:** Developers may blindly trust AI suggestions due to their sophisticated appearance.
    * **Mitigation:** Maintain healthy skepticism and annotate which code sections were AI-suggested during reviews.

## 6.0 Coding Assistant Tool Status

* ðŸŸ¢ **Approved (Government Versions):**
    **Windsurf (Codeium):** Preferred choice. The **Windsurf Government Cloud** is FedRAMP High-authorized.
    **â€‹GitHub Copilot:** Allowed via Enterprise. Requires mandatory opt-out of data training and use of public code filters.
    **Google AI Studio:** Accessible via the Stateâ€™s Google contract; requires access to an enterprise API key through the Maryland Department of Information Technology (DoIT)â€™s [intake process](https://doitmaryland.service-now.com/doit?id=doit).

* ðŸŸ¡ **Experimental / Pilot Only:**
    * **Cursor:** Not FedRAMP-authorized. Use only in sandboxes with CIO approval and **Privacy Mode** (Zero Data Retention) enabled.
    * **Jules:** Allowed for experimental use in sandboxes only; requires a detailed security plan and CIO approval.

* ðŸ”´ **Restricted / Not Recommended:**
    * **Cline:** High autonomous risk and lack of managed accountability; not for production use.
    * **Free/Individual Versions:** Prohibited for state business due to data training defaults.

## 7.0 Agency Compliance and Intake
All use of AI coding assistants must be documented in [the Stateâ€™s AI inventory](https://ai.maryland.gov/ai-inventory) per SB818. Agencies that wish to use unapproved coding assistants must request to use them through [DoITâ€™s intake process](https://doit.maryland.gov/policies/Departmental/Pages/Intake-Process.aspx).

Once you [submit your intake request](https://doitmaryland.service-now.com/doit?id=sc_cat_item&sys_id=90ebe560db6bd300b302e9ec0b9619e0) to use your coding assistant of choice, you will receive a questionnaire which asks questions about the toolâ€™s **data ownership** (State must retain all rights), **data residency** (U.S.-based only), and **vendor indemnification** for infringing code. Be prepared to answer these questions and explain **why** this coding assistant is the best tool to fulfill your business use case.

Marylandâ€™s AI subject matter experts may reach out during intake to share pre-approved coding assistants that you can use instead. If your proposed coding assistant is still the best fit for your use case, the Software Review Board at Marylandâ€™s Department of Information Technology will assess it for approval to use when conducting State business.

## 8.0 Analogy for Understanding

Using an AI coding assistant is like using an advanced cruise control system. While the system can handle the monotony of the highway (boilerplate code), the driver (the developer) must keep their hands on the wheel and eyes on the road.

If the system suggests a dangerous lane change (a security vulnerability) or ignores a Private Property sign (copyright infringement), the driver is the one legally and practically responsible for the outcome.

â€‹The State of Maryland applies this same lens to coding assistants. We pledge to always use AI in service to State residents, employees, and organizations. That involves using AI like coding assistants to deliver state services more effectively. Keeping Marylandâ€™s civil servants in the driverâ€™s seat empowers the State to innovate responsibly.

**â€‹Additional Support:** For additional support, explore Marylandâ€™s AI resources and tools at the stateâ€™s officialâ€‹ [â€‹AI portal](https://ai.maryland.gov/).
